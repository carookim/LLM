{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d682539a",
   "metadata": {},
   "source": [
    "### ÏûêÏó∞Ïñ¥ Í∞êÏÑ± Î∂ÑÏÑù\n",
    "- Í∞êÏÑ±ÏÇ¨Ï†Ñ Í∏∞Î∞ò : ÎØ∏Î¶¨ Ï†ÄÏúºÏù¥Îêú Í∞êÏÑ±Îã®Ïñ¥ ÏÇ¨Ï†Ñ ÏÇ¨Ïö©(Í∑úÏπô Í∏∞Î∞ò)\n",
    "    - TextBlob, AFINNm VADER\n",
    "- Î®∏Ïã†Îü¨Îãù Í∏∞Î∞ò : Îç∞Ïù¥ÌÑ∞Î°ú Î∂ÄÌÑ∞ Ìå®ÌÑ¥ ÌïôÏäµ(ÌÜµÍ≥Ñ Í∏∞Î∞ò)\n",
    "    - TF-IDF Î≤°ÌÑ∞Ìôî\n",
    "    - ÎπàÎèÑÏàò Î≤°ÌÑ∞Ìôî\n",
    "    - Multinomial Naive Bayes\n",
    "    - Î°úÏßÄÏä§Ìã± ÌöåÍ∑Ä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad631e",
   "metadata": {},
   "source": [
    "### ÏÇ¨Ïö© Îç∞Ïù¥ÌÑ∞\n",
    "- NLTK ÏòÅÌôî Î¶¨Î∑∞ (2000Í∞ú)\n",
    "- Îã§ÏùåÏòÅÌôîÎ¶¨Î∑∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28579dc1",
   "metadata": {},
   "source": [
    "#### ÏïåÍ≥†Î¶¨Ï¶ò\n",
    "- textblob\n",
    "- afinn\n",
    "- vader\n",
    "\n",
    "- TF-IDF\n",
    "- CounterVectorizer\n",
    "- Multinomial Naive Bayes\n",
    "- Î°úÏßÄÏä§Ìã± ÌöåÍ∑Ä ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob\n",
    "# ÌäπÏ†ïÎã®Ïñ¥Î•º ÏÑ†Ï†ïÌïòÍ≥†, Í∑∏ Îã®Ïñ¥Í∞Ä ÎÇòÏò¨Í≤ΩÏö∞ Ï†êÏàòÎ•º Ï∂îÍ∞ÄÌïòÍ±∞ÎÇò Í∞êÏ†êÌïúÎã§.\n",
    "# Polarity  Í∑πÏÑ±ÎèÑ\n",
    "# Í∏çÏ†ï(1)Í≥º Î∂ÄÏ†ï(-1)\n",
    "# 0ÏùÄ Ï§ëÎ¶Ω\n",
    "# Subjectivity Ï£ºÍ¥ÄÏÑ±\n",
    "# Í∞ùÍ¥Ä(-1)Í≥º Ï£ºÍ¥Ä(1)\n",
    "# 0ÏùÄ Ï§ëÎ¶Ω\n",
    "\n",
    "# Î¨∏Îß•ÏùÄ Î¨¥ÏãúÌïòÍ≥† Îã®Ïñ¥ Ïó¨Î∂ÄÎ°úÎßå ÌåêÎã®ÌïúÎã§.\n",
    "# Ïù¥ ÏòÅÌôîÎäî ÎÇòÏÅòÏßÄ ÏïäÎã§. -> ÎÇòÏÅòÎã§, ÏïäÎã§ ÏóêÏÑú Í∞êÏ†ê(-)ÏúºÎ°ú Ïù∏Ïãù\n",
    "# Ïû•Ï†ê : Îπ†Î•∏ÏÜçÎèÑ ÌïôÏäµ Î∂àÌïÑÏöî\n",
    "# ÏÇ¨Ïö© : Ïã§ÏãúÍ∞Ñ Í∞êÏÑ± Î∂ÑÏÑù, Ïä§Ìä∏Î¶¨Î∞ç Îç∞Ïù¥ÌÑ∞ -> Îπ†Î•∏ ÌåêÎã®Ïù¥ ÌïÑÏöîÌïú ÏÉÅÌô©Ïóê ÏÇ¨Ïö©ÌïòÍ∏∞ÎèÑ ÌïúÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d202b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Word\n",
    "text = \"TextBlob is amazingly simple to use. What a wonderful library for NLP!\"\n",
    "blob = TextBlob(text)\n",
    "print(blob.sentences)\n",
    "print(blob.words)\n",
    "print(blob.tags)\n",
    "\n",
    "import nltk\n",
    "# nltk.download('brown')\n",
    "print(blob.noun_phrases)\n",
    "\n",
    "# Î¨∏Ïû•, Îã®Ïñ¥, ÌíàÏÇ¨ Îã®ÏúÑÏùò Í∏∞Î≥∏ Î∂ÑÏÑù Í∏∞Îä•ÏùÑ ÏßÄÏõêÌï®ÏùÑ ÌôïÏù∏Ìï† Ïàò ÏûàÎã§.\n",
    "# Îã®Ïñ¥ Î∂ÑÎ¶¨Ïùò Í≤ΩÏö∞ÏóêÎäî Î¨¥ÏóáÏùÑ Í∏∞Ï§ÄÏúºÎ°ú? ^ Í≥µÎ∞±, Î¨∏Ïû•Î∂ÄÌò∏, ÌòïÌÉúÏÜå Î∂ÑÏÑù Í∑úÏπôÏùÑ Í∏∞Ï§Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4512b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Í∞êÏÑ± Î∂ÑÏÑù\n",
    "blob.sentiment\n",
    "# Sentiment(polarity=0.5, subjectivity=0.6785714285714286)\n",
    "\n",
    "# Polarity  Í∑πÏÑ±ÎèÑ\n",
    "# Í∏çÏ†ï(1)Í≥º Î∂ÄÏ†ï(-1)\n",
    "# 0ÏùÄ Ï§ëÎ¶Ω\n",
    "# Subjectivity Ï£ºÍ¥ÄÏÑ±\n",
    "# Í∞ùÍ¥Ä(-1)Í≥º Ï£ºÍ¥Ä(1)\n",
    "# 0ÏùÄ Ï§ëÎ¶Ω\n",
    "\n",
    "# ÏïΩÍ∞Ñ Í∏çÏ†ïÏù¥Í≥†, Ï£ºÍ¥ÄÏ†ÅÏù∏ ÌëúÌòÑÏù¥Îã§.\n",
    "\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff87ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFINN(Lexicon-Based)\n",
    "# Í∞Å Îã®Ïñ¥Ïùò -5 ~ +5Ïùò Ï†êÏàòÎ•º Î∂ÄÏó¨ÌïòÍ≥† Ìï©ÏÇ∞\n",
    "# Ïù¥ ÏòÅÌôîÎäî Ï¢ãÏßÄÎßå Ï¢ãÏßÄÏïäÏùÄ Î∂ÄÎ∂ÑÎèÑ ÏûàÎã§.\n",
    "    # Ï¢ãÎã§ +3 Ï¢ãÎã§ +3 ÏïäÎã§ -3 = +3 > 0 -> Í∏çÏ†ï ÏúºÎ°ú ÌèâÍ∞Ä\n",
    "# Ï°∞Ìöå Î∞©Î≤ï : score = sum(word_sentiment_value)\n",
    "# Î∂ÑÎ•òÍ∑úÏπô\n",
    "    # 0 > score Í∏çÏ†ï\n",
    "    # score < 0 Î∂ÄÏ†ï\n",
    "# Ïù¥Î™®Ìã∞ÏΩòÏßÄÏõê\n",
    "# Í∞ïÎèÑÌëúÌòÑ Ïù∏Ïãù very, really Îì±\n",
    "\n",
    "# Í∞ïÏ°∞ ÏàòÏ†ïÏûê(intensifiers)\n",
    "    # Îß§Ïö∞Ï¢ãÎã§ = 1.5 x (Ï¢ãÎã§Ïùò Ï†êÏàò)\n",
    "\n",
    "# AFINN vs TextBlob\n",
    "# AFINN : Îçî Ï†ïÌôïÌïú Ï†êÏàò Îß§Ìïë\n",
    "# TextBlob : Îçî ÏùºÎ∞òÏ†ÅÏù∏ Ï†ëÍ∑º ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5220e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting afinn\n",
      "  Downloading afinn-0.1.tar.gz (52 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: afinn\n",
      "  Building wheel for afinn (setup.py): started\n",
      "  Building wheel for afinn (setup.py): finished with status 'done'\n",
      "  Created wheel for afinn: filename=afinn-0.1-py3-none-any.whl size=53479 sha256=d5e78352c9a512aa4d0d73e7468f036fd2534ea239a3df9b2abd21038a65bdfb\n",
      "  Stored in directory: c:\\users\\playdata2\\appdata\\local\\pip\\cache\\wheels\\f3\\20\\88\\bd79bf1dfa529d0e4e301372371edf7639514a9f0d337769c3\n",
      "Successfully built afinn\n",
      "Installing collected packages: afinn\n",
      "Successfully installed afinn-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'afinn' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'afinn'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "# %pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab61b0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 4.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "af = Afinn()\n",
    "text1 = \"TextBlob is amazingly simple to use.\"\n",
    "text2 = \"What a wonderful library for NLP!\"\n",
    "score1 = af.score(text1)\n",
    "score2 = af.score(text2)\n",
    "score1, score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER ÏÜåÏÖúÎØ∏ÎîîÏñ¥ ÌÖçÏä§Ìä∏Ïóê ÏµúÏ†ÅÌôî\n",
    "# Ïù¥ ÏòÅÌôîÎäî Ï†ïÎßêÏ†ïÎßê ÌõåÎ•≠Ìï¥!!!\n",
    "# ÌõåÎ•≠ÌïòÎã§ (Í∏∞Î≥∏) + 0.7 Ï†ïÎßêÏ†ïÎßê (Í∞ïÏ°∞) x 1.5\n",
    "# !!! (Î¨∏Ïû•Î∂ÄÎ°úÍ∞ïÏ°∞)  x 1.2\n",
    "\n",
    "# 4Í∞úÏùò Í∞êÏ†ï ÏßÄÏàò\n",
    "    # positive Í∏çÏ†ï ÌôïÎ•† 0 ~ 1\n",
    "    # negative Î∂ÄÏ†ï ÌôïÎ•†\n",
    "    # neutral Ï§ëÎ¶Ω ÌôïÎ•†\n",
    "    # compund Ï¢ÖÌï©Ï†êÏàò -1 ~ 1\n",
    "        # +1 Ïóê Í∞ÄÍπåÏö∏ÏàòÎ°ù Îß§Ïö∞ Í∏çÏ†ïÏ†Å\n",
    "        # -1 Ïóê Í∞ÄÍπåÏö∏ÏàòÎ°ù Îß§Ïö∞ Î∂ÄÏ†ïÏ†Å\n",
    "        # 0 Í∑ºÏ≤òÎùºÎ©¥ Ï§ëÎ¶ΩÏ†Å\n",
    "\n",
    "# Ï¢ÖÌï©Ï†êÏàò Ï°∞Ìöå Î∞©Î≤ï :\n",
    "# score = compound_score / sqrt(compound_score**2 + 0.0625)\n",
    "# score >= 0.05 Í∏çÏ†ï\n",
    "# score <= -0.05 Î∂ÄÏ†ï\n",
    "# Í∑∏ ÏÇ¨Ïù¥( -0.05 < score < 0.05 )Îäî Ï§ëÎ¶Ω\n",
    "\n",
    "# ÎåÄÏÜåÎ¨∏Ïûê Íµ¨Î∂Ñ AMAZING amazing Îã§Î•∏ Ï†êÏàò\n",
    "# :) Í∏çÏ†ï :-( Î∂ÄÏ†ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b047040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Playdata2\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d872e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î¨∏Ïû• : I love this product! It's absolutely amazing üòç\n",
      "Ï†êÏàò : {'neg': 0.0, 'neu': 0.318, 'pos': 0.682, 'compound': 0.862}\n",
      "Î¨∏Ïû• : This is the worst movie I've ever seen...\n",
      "Ï†êÏàò : {'neg': 0.369, 'neu': 0.631, 'pos': 0.0, 'compound': -0.6249}\n",
      "Î¨∏Ïû• : The food was okay, not great but not bad either.\n",
      "Ï†êÏàò : {'neg': 0.149, 'neu': 0.487, 'pos': 0.364, 'compound': 0.4728}\n",
      "Î¨∏Ïû• : I‚Äôm REALLY happy with the results!!!\n",
      "Ï†êÏàò : {'neg': 0.0, 'neu': 0.472, 'pos': 0.528, 'compound': 0.7651}\n",
      "Î¨∏Ïû• : Not good at all. I‚Äôm disappointed.\n",
      "Ï†êÏàò : {'neg': 0.579, 'neu': 0.421, 'pos': 0.0, 'compound': -0.6711}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "sentences = [\n",
    "    \"I love this product! It's absolutely amazing üòç\",\n",
    "    \"This is the worst movie I've ever seen...\",\n",
    "    \"The food was okay, not great but not bad either.\",\n",
    "    \"I‚Äôm REALLY happy with the results!!!\",\n",
    "    \"Not good at all. I‚Äôm disappointed.\",\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    scores = analyzer.polarity_scores(s)\n",
    "    print(f'Î¨∏Ïû• : {s}')\n",
    "    print(f'Ï†êÏàò : {scores}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
