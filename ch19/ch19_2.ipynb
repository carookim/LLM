{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROOrxwYy6My5",
        "outputId": "e2a542ca-94be-4918-eee9-3d0936c8e54f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMBRltXI5zLP"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 필수 라이브러리 임포트\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Transformers 라이브러리\n",
        "from transformers import (\n",
        "    pipeline,                              # 고수준 API - 가장 쉬운 방법\n",
        "    AutoTokenizer,                         # 자동 토크나이저\n",
        "    AutoModelForQuestionAnswering,         # QA 모델 자동 로더 : 모델 패키지 \n",
        "    DistilBertTokenizerFast,              # DistilBERT 고속 토크나이저\n",
        "    DistilBertForQuestionAnswering,        # DistilBERT QA 모델  : 직접가져옴\n",
        "    ElectraTokenizer,                      # ELECTRA 토크나이저 (한글) : 직접가져옴\n",
        "    ElectraForQuestionAnswering,           # ELECTRA QA 모델 (한글) : 직접가져옴\n",
        "    DefaultDataCollator,                   # 기본 데이터 콜레이터\n",
        "    TrainingArguments,                     # 학습 하이퍼파라미터\n",
        "    Trainer,                               # 범용 트레이너\n",
        ")\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsisx17i53k9",
        "outputId": "bf8e9f72-d7d8-4ebd-a2a2-a2264683fbd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "answer1 : {'score': 0.42419037222862244, 'start': 95, 'end': 153, 'answer': 'the process of deriving high-quality information from text'}\n",
            "answer2 : 답변 없음\n"
          ]
        }
      ],
      "source": [
        "question_answer = pipeline(\"question-answering\",model = 'distilbert-base-cased-distilled-squad')\n",
        "\n",
        "context = \"\"\"Text mining, also referred to as text data mining (abbr.: TDM), similar to text analytics,\n",
        "is the process of deriving high-quality information from text. It involves\n",
        "\"the discovery by computer of new, previously unknown information,\n",
        "by automatically extracting information from different written resources.\"\n",
        "Written resources may include websites, books, emails, reviews, and articles.\n",
        "High-quality information is typically obtained by devising patterns and trends\n",
        "by means such as statistical pattern learning. According to Hotho et al. (2005)\n",
        "we can distinguish between three different perspectives of text mining:\n",
        "information extraction, data mining, and a KDD (Knowledge Discovery in Databases) process.\"\"\"\n",
        "\n",
        "question1 = \"What is text mining?\"\n",
        "question2 = \"What are the perspectives of text mining?\"\n",
        "\n",
        "# 질의 응답 수행\n",
        "answer1 = question_answer(context=context, question=question1)\n",
        "answer2 = question_answer(context=context, question=question2)\n",
        "if answer1['score'] < 0.1:\n",
        "  print(f'answer1 : 답변 없음')\n",
        "else:\n",
        "  print(f\"answer1 : {answer1['answer']}\")\n",
        "if answer2['score'] < 0.1:\n",
        "  print(f'answer2 : 답변 없음')\n",
        "else:\n",
        "  print(f\"answer2 : {answer2['answer']}\")\n",
        "\n",
        "# AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "inputs = tokenizer(question1, context, return_tensors=\"pt\").to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "start_score = outputs.start_logits\n",
        "end_score  = outputs.end_logits\n",
        "answer_start = torch.argmax(start_score)\n",
        "answer_end = torch.argmax(end_score)\n",
        "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end+1]))\n",
        "print(f\"answer1 : {answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#SQuAD 데이터셋 로드 분석\n",
        "# 스탠포드 대학에서 공개한 질의응답 벤치마크 :\n",
        "# Extractive QA(추출 기반 질의응답) 모델의 표준\n",
        "# 문서 안에 이미 존재하는 답을 골라낸다.\n",
        "\n",
        "squad = load_dataset('squad', split = 'train[:5000]', trust_remote = True)\n",
        "squad = squad.train_test_split(test_size=0.2, seed=42)\n",
        "squad"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "conda_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
