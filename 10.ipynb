{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch12 01.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f02335",
   "metadata": {},
   "source": [
    "### 가상환경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb845064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n [이름] python=[버전]\n",
    "# conda activate [이름]\n",
    "\n",
    "# conda deactivate\n",
    "# conda remove-n [이름] --all\n",
    "\n",
    "# tensorflow 안전지원 파이썬 버젼 3.11 로 가상환경 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef9264",
   "metadata": {},
   "source": [
    "### 딥러닝 감성분석\n",
    "- 입력 ~ 1D Convolution + poling 반복 단계 과정정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 감성분석 - 딥러닝에 넣을 데이터 변환 과정 => 정수배열\n",
    "\n",
    "# 입력 -> 토큰화 및 시퀀스 변화 -> 패딩(고정길이화) -> 임베딩(단어->벡터화)\n",
    "# -> 1D Convolution + poling 반복 -> Flatten ->  Dense(은닉) -> 출력(softmax, 이진분류)\n",
    "# -> 학습(Adam + binary_CrossEntropy) -> 검증 / 테스트 평가 -> 시각화 \n",
    "\n",
    "# 시퀀스 단계에서 문장별로 숫자로 변환한 숫자 리스트의 길이를 맞추는 단계, 패딩\n",
    "# 임베딩 단계에서 단어별의 관계와 의미를 수치로 표시한다. 벡터화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c9dff",
   "metadata": {},
   "source": [
    "- 말뭉치 로딩(nltk) 데이터 로딩\n",
    "- 토큰화(빈고 기반 인덱싱) 텍스트를 숫자로 변환\n",
    "- 시퀀스 패딩 고정길이 배치 구성\n",
    "- 임베딩 단어를 dense vector 표현학습\n",
    "- 임베딩 발전\n",
    "    - 한계 : 작은 데이터에서는 일반화 부족\n",
    "    - 발전 : 사전학습(Word2vec) , 문맥적 임베딩(Bert, GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90352354",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# sample data\n",
    "texts = [\n",
    "    'I really love this movie',\n",
    "    'I hate this boring film',\n",
    "    'love love great film'\n",
    "] # texts에 딕셔너리 형태도 들어가던데 그건 뭔지 ^\n",
    "\n",
    "# 토큰화 객체(최대 단어 10, oov 토큰 지정)\n",
    "tokenizer = Tokenizer(num_words=10, oov_token='UNK') # ^\n",
    "# num_words\n",
    "# 상위 10개의 단어만 사전에 포함한다.\n",
    "\n",
    "# oov_token\n",
    "# 모델이 학습할 때 보지 못한 단어를\n",
    "# 하나의 특별한 토큰으로 치환할때 무엇으로 치환할지 설정\n",
    "\n",
    "# num_words에 지정된 10의 값은 ovv_token까지 합해서 10개의 단어 사전을 생성한다.\n",
    "# 그래서 단어인덱스에서 조회한\n",
    "# 11번째 마지막 항목 'great': 10 은 실제로 단어사전에 해당되지않는다.\n",
    "\n",
    "tokenizer.fit_on_texts(texts)\n",
    "print(f'단어 인덱스 : {tokenizer.word_index}')\n",
    "\n",
    "# 시퀀스로 변환 ^\n",
    "seqs = tokenizer.texts_to_sequences(texts)\n",
    "print(f'원본 시퀀스 : {seqs}')\n",
    "\n",
    "# 패딩(최대길이를 6)\n",
    "padded = pad_sequences(seqs,maxlen=6,padding='post') # ^\n",
    "# padding='post'\n",
    "# padding=pre'\n",
    "print(f'패딩결과 : {padded}, 사이즈 : {padded.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ca552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 : 임베딩 레이어\n",
    "import tensorflow as tf\n",
    "# 패딩된 시퀀스 padded\n",
    "vocab_size = 11 # unk 포함 단어인덱스 최대값 + 1\n",
    "embed_dim = 4 # 작은 차원\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=embed_dim,input_length=6)\n",
    "]) # ^\n",
    "embeddings = model.predict(padded)\n",
    "print(f'임베딩 텐서 모양 : {embeddings.shape}') # (3, 6, 4)\n",
    "print(f'첫 문장 첫 단어 벡터 : {embeddings[0,0,:]}')\n",
    "\n",
    "# output_dim = 4\n",
    "# 단어 하나가 [0.12, -0.53, 0.88, 0.03]처럼 4개의 실수로 표현\n",
    "\n",
    "# output_dim 출력 차원수는 4차원으로 적절히 설정\n",
    "\n",
    "# 임베딩된 단어 벡터를 시각화 ^\n",
    "# 단어 간 의미적 유사도 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a66794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Convolution\n",
    "# 1D Convolution은 \"문장 속 특징을 찾는 탐지기\",\n",
    "# Pooling은 \"중요한 것만 남기는 압축기\",\n",
    "# 반복하면\n",
    "# \"단어 조합 → 문장 전체 특징\"까지 점점 높은 수준의 감정 특징을 뽑을 수 있다.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# 임의 시퀀스(배치=1, 길이=6, 임베딩=4)\n",
    "x= np.random.randn(1,6,4).astype('float32')\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "    filters = 2 # 2개의 패턴을 감지\n",
    "    ,kernel_size = 3 # 3-gram\n",
    "    ,activation = 'relu' # 활성화 함수 설정\n",
    ")\n",
    "# tf.keras.layers.Conv1D(2, 3, activation='relu')\n",
    "y = conv(x)\n",
    "print(f'입력 : {x.shape}')\n",
    "print(f'출력 : {y.shape}')\n",
    "print(f'출력값 : {y.numpy()}')\n",
    "\n",
    "# 입력 : (1, 6, 4)\n",
    "# 출력 : (1, 4, 2)\n",
    "# kernel_size = 3 으로 6개의 값을 3개씩 차례로 겨치게 묶어서 출력[1]은 4개\n",
    "# filters = 2로 지정 했으므로 출력[2]은 2개\n",
    "\n",
    "# 근데 여기서 다른 걸로 사용해서 패턴을 구할수는 없는건지 ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f19b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaxPooling\n",
    "pool = tf.keras.layers.MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ade7b8",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca971ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer # 단어를 단어사전, 단어를 숫자로 변경\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # 길이 맞추기\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "texts = [\n",
    "    'I really love this movie', # 긍정\n",
    "    'I hate this boring film', # 부정\n",
    "    'great love film', # 긍정\n",
    "    'boring hate film' # 부정\n",
    "]\n",
    "\n",
    "labels = np.array([0,1,0,1]) # 긍정 : 0 , 부정 : 1\n",
    "\n",
    "# 토큰화\n",
    "tokenizer = Tokenizer(num_words=10,oov_token='UNK')\n",
    "tokenizer.fit_on_texts(texts) # 단어 사전 생성\n",
    "# 시퀀스화\n",
    "seqs = tokenizer.texts_to_sequences(texts)\n",
    "    # 단어사전을 기반으로 단어들을 숫자로 변경()\n",
    "# 길이 맞추기\n",
    "x = pad_sequences(seqs,maxlen=6,truncating='post')\n",
    "\n",
    "# 임베딩\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim = 11, output_dim = 8, input_length = 6),\n",
    "    tf.keras.layers.Conv1D(16,3,activation='relu'), # ^\n",
    "    # tf.keras.layers.Conv1D(filters, kernel_size, activation=...)\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(8,activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    # 마지막 출력 설정값에 어울리는 활성화함수를 선정 ^ :\n",
    "        # 1개 : sigmoid\n",
    "        # 2개 : softmax\n",
    "    # ^\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc']) # ^\n",
    "# binary_crossentropy\n",
    "# binary_crossentropy는 정답이 0 또는 1인 이진분류에서 사용되는 손실함수\n",
    "# 모델이 예측한 확률이 정답(0 or 1)과 얼마나 차이나는지를 계산해 손실값으로 나타낸다.\n",
    "# 예측이 정답에 가까울수록 손실값은 작아지고,\n",
    "# 멀수록 커져서 모델이 더 정확해지도록 학습을 유도한다.\n",
    "# -> 옵티마이저는 손실값이 최소화, 작아지는 쪽으로 가중치를 조절한다.\n",
    "\n",
    "history = model.fit(x,labels,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x)\n",
    "print(f\"최종훈련 정확도 : {history.history['acc'][-1]}\")\n",
    "print(f'{preds}')\n",
    "print(f'라벨 : {labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f6eb51",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08385507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b2aa494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.1-cp311-cp311-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\playdata2\\miniconda3\\envs\\conda_venv\\lib\\site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\playdata2\\miniconda3\\envs\\conda_venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\playdata2\\miniconda3\\envs\\conda_venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\playdata2\\miniconda3\\envs\\conda_venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\playdata2\\miniconda3\\envs\\conda_venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.7-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 8.1/8.1 MB 38.7 MB/s  0:00:00\n",
      "Downloading contourpy-1.3.3-cp311-cp311-win_amd64.whl (225 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 65.0 MB/s  0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp311-cp311-win_amd64.whl (73 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   -------------------- ------------------- 3/6 [cycler]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   ---------------------------------------- 6/6 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 pyparsing-3.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk 데이터로드\n",
    "import nltk\n",
    "nltk.download('mocie_reviews')\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d862ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재현성 시드 고정\n",
    "# 재현성을 위해 랜덤 시드를 고정한다.\n",
    "# 넘파이, 텐서플로우, 파이썬 기본 random 모듈의 시드를 모두 42로 설정\n",
    "import random\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcdb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩\n",
    "ids = movie_reviews.fileids() # ^\n",
    "# .fileids()\n",
    "# NLTK 코퍼스(corpus) 안에 포함된 파일들의\n",
    "# ID(이름 목록) 을 가져오는 메서드입니다.\n",
    "\n",
    "# ID를 순환문으로 돌려, 전체 데이터의 행과, 카테고리를 추출한다.\n",
    "reviews = [movie_reviews.raw(id) for id in ids]\n",
    "categories = [movie_reviews.categories(id) for id in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76cad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# truncating : 자른다.\u001b[39;00m\n\u001b[32m     15\u001b[39m         \u001b[38;5;66;03m# 기본값은 앞을 자른다. 'pre'\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# padding : 채운다.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 라벨인코딩\u001b[39;00m\n\u001b[32m     24\u001b[39m label_map = {\u001b[33m'\u001b[39m\u001b[33mpos\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m0\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mneg\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m1\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m y = np.array(\u001b[43m[\u001b[49m\u001b[43mlabel_map\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# y = np.array([label_map[c[0]] for c in categories]) ^\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# train / test 분할\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# truncating : 자른다.\u001b[39;00m\n\u001b[32m     15\u001b[39m         \u001b[38;5;66;03m# 기본값은 앞을 자른다. 'pre'\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# padding : 채운다.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 라벨인코딩\u001b[39;00m\n\u001b[32m     24\u001b[39m label_map = {\u001b[33m'\u001b[39m\u001b[33mpos\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m0\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mneg\u001b[39m\u001b[33m'\u001b[39m:\u001b[32m1\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m y = np.array([\u001b[43mlabel_map\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m categories])\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# y = np.array([label_map[c[0]] for c in categories]) ^\u001b[39;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# train / test 분할\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터\n",
    "max_words = 10000 # 최대 단어수\n",
    "    # 이전버젼에선 max_words가 num_words\n",
    "maxlen = 500 # 문서길이\n",
    "embed_dim = 64 # 임베딩 차원\n",
    "batch_size = 256 # batch_size\n",
    "epochs = 15 # epochs\n",
    "\n",
    "# 토큰화 + 시퀀스 변화 + 패딩\n",
    "tokenizer = Tokenizer(num_words = max_words, oov_token='UNK')\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "seqs = tokenizer.texts_to_sequences(reviews)\n",
    "x = pad_sequences(seqs,maxlen=maxlen,truncating='post') # ^\n",
    "    # truncating : 자른다.\n",
    "        # 기본값은 앞을 자른다. 'pre'\n",
    "    # padding : 채운다.\n",
    "        # 기본값은 앞을 채운다. 'pre'\n",
    "\n",
    "# 체이닝 기법으로\n",
    "# tokenizer.fit_on_texts(reviews).texts_to_sequences(reviews) 이런식으로\n",
    "# 하려고했지만 이럴려면 그값으로 바로 반환하는 기능이있어야 한다. ^\n",
    "\n",
    "# 라벨인코딩\n",
    "label_map = {'pos':0,'neg':1}\n",
    "y = np.array([label_map.get(c) for c in categories])\n",
    "# y = np.array([label_map[c[0]] for c in categories]) ^\n",
    "\n",
    "# train / test 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, stratify=y, random_state=42, test_size=0.2)\n",
    "\n",
    "# 모델구성\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_words+1,output_dim=embed_dim,input_length=maxlen),\n",
    "    tf.keras.layers.Conv1D(128,3,activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(), # ^\n",
    "    tf.keras.layers.Conv1D(256,3,activation='relu'),\n",
    "    # tf.keras.layers.GlobalAveragePooling1D() # ^\n",
    "    tf.keras.layers.MaxPool1D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64,activation='relu'), # 이 단계가 있는 이유 ^\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid') # ^ sigmoid와 softmax\n",
    "])\n",
    "\n",
    "# 1)\n",
    "# 두가지의 풀링툴의 차이 : MaxPool1D 와 GlobalAveragePooling1D\n",
    "# MaxPool1D: 여러 값 중 가장 큰 값만 뽑아서 중요한 특징만 남긴다.\n",
    "# GlobalAveragePooling1D: 전체 값을 평균내서 전체적인 흐름이나 대표값을 만든다.\n",
    "    # 이 경우에는 Flatten이 필요없다.\n",
    "    \n",
    "# 차이점:\n",
    "# MaxPool1D는 강한 특징 강조\n",
    "# GlobalAveragePooling1D는 전체적인 정보 요약에 쓰인다.\n",
    "\n",
    "# 2)\n",
    "# tf.keras.layers.Dense(64,activation='relu'), 이 단계가 있는 이유\n",
    "\n",
    "# 3)\n",
    "# 출력층에서의 활성화 함수 선택, sigmoid와 softmax\n",
    "\n",
    "####\n",
    "# 컴파일 compile\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# 콜백 callbacks (선택)\n",
    "import tensorflow as tf\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\n",
    "\n",
    "# 학습 fit\n",
    "history = model.fit(\n",
    "    x_train,y_train,epochs=epochs,batch_size=batch_size,validation_split=0.2\n",
    "    #, callbacks=[es]\n",
    "    ) # ^\n",
    "\n",
    "# validatioin_split\n",
    "\n",
    "# callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca11a17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - acc: 0.5000 - loss: 0.3964\n",
      "test loss : 0.39642032980918884, test acc : 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 학습결과 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(history.history['acc'],label='train')\n",
    "plt.plot(history.history['val_acc'],label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 테스트 평가\n",
    "test_loss, test_acc = model.evaluate(x_test,y_test)\n",
    "print(f'test loss : {test_loss}, test acc : {test_acc}')\n",
    "\n",
    "# 임의의 데이터로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a09cf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 64])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1d 배치크기, 시퀀스길이, 채널수\n",
    "# 배치크기=32, 시퀀스길이=10, 채널수=64\n",
    "x = tf.random.normal(shape=(32,10,64))\n",
    "\n",
    "# Flatten\n",
    "print(tf.keras.layers.Flatten()(x).shape)\n",
    "\n",
    "# GlobalAveragePooling1D\n",
    "tf.keras.layers.GlobalAveragePooling1D()(x).shape\n",
    "    # 각 채널 Feature map 마다 평균"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
