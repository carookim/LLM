{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e76ce601",
   "metadata": {},
   "source": [
    "- nltk 영화리뷰 데이터로 BERT 감성분석 모델 완성\n",
    "    - 데이터 로드 및 분할\n",
    "    - BERT 토큰화\n",
    "    - pytorch Dataset 구성\n",
    "    - 모델 학습\n",
    "    - 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357ccb0",
   "metadata": {},
   "source": [
    "#### 모듈 및 사용할 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6faf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2612a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53012879",
   "metadata": {},
   "source": [
    "#### 데이터 셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd726c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 다운로드\n",
    "# 라벨은 pos : 1, neg : 0\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import movie_reviews\n",
    "ids = movie_reviews.fileids()\n",
    "reviews = [movie_reviews.raw(id) for id in movie_reviews.fileids()]\n",
    "categories = [movie_reviews.categories(id)[0] for id in movie_reviews.fileids()]\n",
    "labels = [1 if label =='pos' else 0 for label in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91711194",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reviews), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11a4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_text,test_text,train_label,test_label = train_test_split(reviews,labels,random_state=42,stratify=labels,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저\n",
    "BERT_MOEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MOEL_NAME)\n",
    "# 훈련 / 테스트 데이터 토큰화\n",
    "train_encodings = tokenizer(train_text, truncation=True, padding = True,return_tensors='pt', max_length=512) \n",
    "test_encodings = tokenizer(train_text, truncation=True,padding=True,return_tensors='pt', max_length=512)\n",
    "train_encodings['input_ids'].shape, test_encodings['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c425d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataset 구성\n",
    "class MovieReciewDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,encodings,labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self,idx):\n",
    "        item = {key :val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "train_dataset = MovieReciewDataset(train_encodings, train_label)\n",
    "test_dataset = MovieReciewDataset(train_encodings, test_label)\n",
    "print(f'훈련 샘플 수 : {len(train_dataset)}')\n",
    "print(f'테스트 샘플 수 : {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d3629",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ec324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BERT_MOEL_NAME, num_labels=2)\n",
    "print(f'파라미터 수 : {sum(p.numel() for p in model.parameters())}')\n",
    "print(f'학습 가능한 파라미터 : {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16093afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0fdf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 매트릭스\n",
    "import evaluate\n",
    "accuracy = evaluate.load('accuracy')\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe996fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad654d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "print(accelerate.__version__)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to = 'none'  # W&B TensorBoard 자동 로딩 모두 끔\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "print(f'에포크 : {training_args.num_train_epochs}')\n",
    "print(f'배치크기 : {training_args.per_device_train_batch_size}')\n",
    "print(f'학습률 : {training_args.learning_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d196424",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 학습\n",
    "train_result = trainer.train()\n",
    "print(f'총 학습시간 : {train_result.metrics[\"train_runtime\"]}')\n",
    "print(f'최종손실 : {train_result.metrics[\"train_loss\"]}')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_result = trainer.evaluate()\n",
    "print(f'테스트 정확도 : {eval_result[\"eval_accuracy\"]}')\n",
    "# 예측수행\n",
    "predictions = trainer.predict(test_dataset)\n",
    "pred_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "# 분류리포트\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0054645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_reviews = [\n",
    "    \"This movie is absolutely fantastic! The plot is engaging and the acting is superb.\",\n",
    "    \"Terrible film. Waste of time and money. Would not recommend to anyone.\",\n",
    "    \"It's an okay movie. Nothing special but not terrible either.\",\n",
    "    \"Brilliant masterpiece! One of the best films I've ever seen in my life.\",\n",
    "    \"Boring and predictable. I fell asleep halfway through.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bdc42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5eccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.eval()\n",
    "for i,review in enumerate(test_reviews):\n",
    "  inputs = tokenizer(review,\n",
    "                     return_tensors=\"pt\",\n",
    "                     truncation=True,\n",
    "                     padding=True,\n",
    "                     max_length=512\n",
    "                     )\n",
    "  inputs   = {k:v.to(device) for k,v in inputs.items()}\n",
    "  with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits =  outputs.logits\n",
    "    probs = torch.softmax(logits, dim=-1)[0]\n",
    "    pred_class = torch.argmax(probs).item()\n",
    "  confidence = probs[pred_class].item()\n",
    "  print(f'문장 : {review}')\n",
    "  print(f'예측 : {pred_class}')\n",
    "  print(f'긍정 : {probs[1].item():.4f}')\n",
    "  print(f'부정 : {probs[0].item():.4f}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
