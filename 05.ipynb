{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06 - topic.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09866b97",
   "metadata": {},
   "source": [
    "##### 토픽 모델링\n",
    "##### LDA 문서 컬렉션에서 주제를 찾아내는 생성 모델\n",
    "- document : 여러 topics의 혼합\n",
    "- topic : 여러 word의 분포\n",
    "- word : 특정 topic에서 생성된 단어\n",
    "- 문서들은 topic의 혼합으로 구성\n",
    "    - 뉴스 기사\n",
    "        - 70% 정치 20% 경제 10% 스포츠\n",
    "    - 토픽은 단어 분포를 갖는다\n",
    "        - 정치 {선거 : 0.2, 대통령 : 0.15, 정부 : 0.1 ...}\n",
    "        - 경제 {주식 : 0.25, 금리 : 0.2, 은행 : 0.15}\n",
    "- 모든 문서를 토픽의 혼합, 토픽별 단어 분포를 랜덤하게 초기화\n",
    "    - 과정을 반복하면\n",
    "        - 각 단어가 어떤 토픽에서 났는 지 추정\n",
    "        - 각 문서의 토픽 비율을 업데이트\n",
    "        - 각 토픽의 단어 분포를 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de0aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 설치\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3496ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Python 프로그래밍은 매우 강력하고 배우기 쉬워요\",\n",
    "    \"머신러닝은 인공지능의 핵심 기술입니다\",\n",
    "    \"자연어처리는 NLP라고도 불립니다\",\n",
    "    \"딥러닝은 신경망을 이용한 학습 방법입니다\",\n",
    "    \"데이터 분석은 통계학에 기반합니다\",\n",
    "    \"파이썬으로 머신러닝 모델을 만들 수 있습니다\",\n",
    "    \"인공지능 기술은 빠르게 발전하고 있습니다\",\n",
    "    \"자연어처리 모델은 텍스트를 이해할 수 있어요\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "189505d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 단어 행렬 : (8, 36)\n",
      "단어목록 : ['nlp라고도' 'python' '강력하고' '기반합니다' '기술은' '기술입니다' '데이터' '딥러닝은' '만들' '매우'\n",
      " '머신러닝' '머신러닝은' '모델은' '모델을' '발전하고' '방법입니다' '배우기' '분석은' '불립니다' '빠르게' '쉬워요'\n",
      " '신경망을' '이용한' '이해할' '인공지능' '인공지능의' '있습니다' '있어요' '자연어처리' '자연어처리는' '텍스트를'\n",
      " '통계학에' '파이썬으로' '프로그래밍은' '학습' '핵심'] 단어목록 개수 : 36\n"
     ]
    }
   ],
   "source": [
    "# 단어 벡터화\n",
    "cv = CountVectorizer(\n",
    "    max_features=50,\n",
    "    stop_words=['은','는','이','가','을','를','그','그리고']\n",
    ")\n",
    "\n",
    "doc_term_matrix = cv.fit_transform(documents)\n",
    "feature_names = cv.get_feature_names_out()\n",
    "print(f'문서 단어 행렬 : {doc_term_matrix.shape}')\n",
    "print(f'단어목록 : {feature_names} 단어목록 개수 : {len(feature_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cadf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 - 주세 행렬 : (8, 3)\n",
      "각 주제별 사우이 단어 ---\n",
      "[topic[0.38300407 0.37702435 0.37634052 0.37702966 1.31854621 1.31159533\n",
      " 0.37540282 0.38207067 0.37989072 0.36592429 0.37165923 1.30887914\n",
      " 1.31775912 0.37670117 1.30433248 0.37908538 0.37405174 0.37657625\n",
      " 0.37955473 1.30006301 0.38374464 0.37044813 0.36978073 1.30897987\n",
      " 1.31238986 1.30769969 1.3052814  1.30522693 1.30416118 0.3872354\n",
      " 1.31023919 0.37600688 0.37379224 0.38215243 0.38554479 1.31254376]]\n",
      "기술은 : 1.3185\n",
      "\n",
      "모델은 : 1.3178\n",
      "\n",
      "핵심 : 1.3125\n",
      "\n",
      "인공지능 : 1.3124\n",
      "\n",
      "기술입니다 : 1.3116\n",
      "\n",
      "[topic[0.37413448 0.37614024 0.37497223 1.30655712 0.38423062 0.38868142\n",
      " 1.31035943 0.37429034 1.30804094 0.38916196 1.30910415 0.37706184\n",
      " 0.37692488 1.31085849 0.37352171 0.37520832 0.38458543 1.30953655\n",
      " 0.38055308 0.38575759 0.37373533 0.37634603 0.38054559 0.38031358\n",
      " 0.36956293 0.37627296 1.31275362 0.38136682 0.38037569 0.37938594\n",
      " 0.3663937  1.30751541 1.30872303 0.39619409 0.37726879 0.38106059]]\n",
      "있습니다 : 1.3128\n",
      "\n",
      "모델을 : 1.3109\n",
      "\n",
      "데이터 : 1.3104\n",
      "\n",
      "분석은 : 1.3095\n",
      "\n",
      "머신러닝 : 1.3091\n",
      "\n",
      "[topic[1.31306673 1.3134711  1.3181743  0.36950958 0.37175109 0.37496421\n",
      " 0.36854522 1.30807949 0.37212974 1.31908455 0.37298001 0.37663304\n",
      " 0.38384912 0.37015793 0.36815124 1.308936   1.30988382 0.38389642\n",
      " 1.30839923 0.38050378 1.30374104 1.30950454 1.30978843 0.37367824\n",
      " 0.39160674 0.38208829 0.37338435 0.38389338 0.38517935 1.30724654\n",
      " 0.37672257 0.37355843 0.37757905 1.30984254 1.30747443 0.38905328]]\n",
      "매우 : 1.3191\n",
      "\n",
      "강력하고 : 1.3182\n",
      "\n",
      "python : 1.3135\n",
      "\n",
      "nlp라고도 : 1.3131\n",
      "\n",
      "배우기 : 1.3099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LDA 모델 생성\n",
    "lda_model = LatentDirichletAllocation(\n",
    "    n_components=3 # 토픽(주제) 개수\n",
    "    ,random_state=  42\n",
    "    ,max_iter=20\n",
    "    ,learning_method='online' # batch ( 모든 데이터를 한번에 다써서 한번 학습), online(미니배치)\n",
    ")\n",
    "# 모델 학습\n",
    "lda_output = lda_model.fit_transform(doc_term_matrix)\n",
    "print(f'문서 - 주제 행렬 : {lda_output.shape}')\n",
    "#\n",
    "\n",
    "# 각 주제 별로 상위 단어 출력\n",
    "def display_topic(model, feature_names, n_top_words =5):\n",
    "    print(f'각 주제별 사우이 단어 ---')\n",
    "    for topic_idxm, topic in enumerate(model.components_):\n",
    "        # 가장 높은 가중치를 가진 단어의 인덱스 호출\n",
    "        top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        top_weights = [topic[i] for i in top_words_idx]\n",
    "        print(f'[topic{topic}]')\n",
    "        for word,weight in zip(top_words,top_weights):\n",
    "            print(f'{word} : {weight:.4f}')\n",
    "            print()\n",
    "display_topic(lda_model,feature_names, n_top_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2713e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 문서의 주요 주제------------\n",
      "문서 : 0 topic : 2 비율 : 0.9036\n",
      "원문 : Python 프로그래밍은 매우 강력하고 배우기 쉬워요\n",
      "\n",
      "문서 : 1 topic : 0 비율 : 0.8650\n",
      "원문 : 머신러닝은 인공지능의 핵심 기술입니다\n",
      "\n",
      "문서 : 2 topic : 2 비율 : 0.8312\n",
      "원문 : 자연어처리는 NLP라고도 불립니다\n",
      "\n",
      "문서 : 3 topic : 2 비율 : 0.8876\n",
      "원문 : 딥러닝은 신경망을 이용한 학습 방법입니다\n",
      "\n",
      "문서 : 4 topic : 1 비율 : 0.8655\n",
      "원문 : 데이터 분석은 통계학에 기반합니다\n",
      "\n",
      "문서 : 5 topic : 1 비율 : 0.8867\n",
      "원문 : 파이썬으로 머신러닝 모델을 만들 수 있습니다\n",
      "\n",
      "문서 : 6 topic : 0 비율 : 0.8855\n",
      "원문 : 인공지능 기술은 빠르게 발전하고 있습니다\n",
      "\n",
      "문서 : 7 topic : 0 비율 : 0.8876\n",
      "원문 : 자연어처리 모델은 텍스트를 이해할 수 있어요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 각 문서의 주요 주제\n",
    "print(f'각 문서의 주요 주제------------')\n",
    "for doc_idx, doc in enumerate(lda_output):\n",
    "    main_topic = np.argmax(doc)\n",
    "    confidence = doc[main_topic]\n",
    "    print(f'문서 : {doc_idx} topic : {main_topic} 비율 : {confidence:.4f}')\n",
    "    print(f'원문 : {documents[doc_idx]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c87c5740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./smaple.csv', <http.client.HTTPMessage at 0x1c5ffda7680>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 청와대 국민청원 데이터로드\n",
    "import os\n",
    "import urllib.request\n",
    "import ssl\n",
    "url = 'https://s3.ap-northeast-2.amazonaws.com/data10902/petition/petition_sampled.csv'\n",
    "\n",
    "# ssl 인증서 무시\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "urllib.request.urlretrieve(url,'./smaple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6bc0cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answered</th>\n",
       "      <th>votes</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2017-11-17</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>일자리</td>\n",
       "      <td>국토교통부와 한국주택협회가 행한 부당한 행위와 권력남용에 대한 내용을 청원드립니다.</td>\n",
       "      <td>안녕하세요? 존경하고 지지하는 문재인 대통령님!\\n저는 성남시 분당구 정자동 주택전...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>보건복지</td>\n",
       "      <td>살려주세요..</td>\n",
       "      <td>안녕하십니까?\\n저는 올해 63세된 홀로 사는 늙은 여자입니다...\\n작년 중복날 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>136</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>육아/교육</td>\n",
       "      <td>고등학교 교육 내용 수준을 낮춰주시고 실용적인 내용을 담아주세요!</td>\n",
       "      <td>저는 광주에 사는 중3 학생입니다. 고등학교 가기 직전의 학년이라 어느 때보다 고등...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>기타</td>\n",
       "      <td>한국문화에 창조적요소를 심자</td>\n",
       "      <td>안녕하십니까\\n저는 92년 한국을 알게된  종국동포 입니다.\\n[저는 한 중소기업에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>148</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017-11-18</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>외교/통일/국방</td>\n",
       "      <td>다문화정책 및 할랄 인증 제도</td>\n",
       "      <td>대한민국과 국민을 위해 밤낮 없이 수고하시는 대통령을 비롯한 위정자 분들께\\n대한민...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  ...                                            content\n",
       "0          58  ...  안녕하세요? 존경하고 지지하는 문재인 대통령님!\\n저는 성남시 분당구 정자동 주택전...\n",
       "1          63  ...  안녕하십니까?\\n저는 올해 63세된 홀로 사는 늙은 여자입니다...\\n작년 중복날 ...\n",
       "2         136  ...  저는 광주에 사는 중3 학생입니다. 고등학교 가기 직전의 학년이라 어느 때보다 고등...\n",
       "3         141  ...  안녕하십니까\\n저는 92년 한국을 알게된  종국동포 입니다.\\n[저는 한 중소기업에...\n",
       "4         148  ...  대한민국과 국민을 위해 밤낮 없이 수고하시는 대통령을 비롯한 위정자 분들께\\n대한민...\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\KIM\\\\LLM\\\\smaple.csv\",nrows=1000)\n",
    "df.head()\n",
    "# ^ 한글 깨지는 경우 ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63c1d6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ce4ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata2\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countvectoize 형태 : (1000, 1827)\n"
     ]
    }
   ],
   "source": [
    "# 한국어 전처리\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "# 명사만 ㅡ 그리고 한글자 이상만\n",
    "def tokenizer(doc):\n",
    "    return [ token for token in okt.nouns(doc) if len(token) > 1 ]\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    max_features=10000,\n",
    "    stop_words=['은','는','이','가','을','를','그','그리고'],\n",
    "    min_df=5,\n",
    "    max_df=0.5,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "pet_cv = cv.fit_transform(df.content)\n",
    "print(f'countvectoize 형태 : {pet_cv.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dab2f934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA 모델학습\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import time #시간측정\n",
    "lda = LatentDirichletAllocation(n_components=len(df.category.unique())\n",
    "                                ,n_jobs=-1\n",
    "                                ,random_state=42\n",
    "                                )\n",
    "pet_topics = lda.fit_transform(pet_csv)\n",
    "elapsed_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be0d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토픽트렌드 분석\n",
    "# 시간 정보 추출\n",
    "# 토픽데이터 프레임 생성\n",
    "# 기존 데이터프레임에서 추출한 시간정보 추가"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
