{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1763435338250,
     "user": {
      "displayName": "새우",
      "userId": "07446014884892897773"
     },
     "user_tz": -540
    },
    "id": "1Lc0Bm2bW8QB"
   },
   "outputs": [],
   "source": [
    "# Attention Mask : 실제토큰 1 / 0 패딩\n",
    "# Token Type IDS(Segment IDs) : 두 개의 문장(A / B) 구성될때 각 토큰이 어느 문장에 속하는지 알려주는 임베딩\n",
    "# CLS Token Pooling : [CLS] + token + [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1763435338895,
     "user": {
      "displayName": "새우",
      "userId": "07446014884892897773"
     },
     "user_tz": -540
    },
    "id": "VFqr4TTFW_bG",
    "outputId": "78d0cd5b-c5fe-4b31-db16-cd6c3b934cc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영문 : Hello world\n",
      "토큰 : ['hello', 'world']\n",
      "ID : [7592, 2088]\n",
      "역변환 : hello world\n",
      "\n",
      "영문 : unbelievable performance\n",
      "토큰 : ['unbelievable', 'performance']\n",
      "ID : [23653, 2836]\n",
      "역변환 : unbelievable performance\n",
      "\n",
      "영문 : COVID-19 pandamic\n",
      "토큰 : ['co', '##vid', '-', '19', 'panda', '##mic']\n",
      "ID : [2522, 17258, 1011, 2539, 25462, 7712]\n",
      "역변환 : covid - 19 pandamic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Bert Tokenizer : 단어를 의미있는 조각(subword)로 나눕니다 unbelievable \"un\" 'believ\" \"able\"\n",
    "from transformers import BertTokenizer\n",
    "# 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "sentences = [\n",
    "    \"Hello world\",\n",
    "    \"unbelievable performance\",\n",
    "    \"COVID-19 pandamic\"\n",
    "]\n",
    "\n",
    "# Bert Tokenizer 내부로직 과정\n",
    "for sentence in sentences :\n",
    "  # 토큰화\n",
    "  tokens = tokenizer.tokenize(sentence)\n",
    "  print(f'영문 : {sentence}')\n",
    "  print(f'토큰 : {tokens}')\n",
    "\n",
    "  # 변환\n",
    "  ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "  print(f'ID : {ids}')\n",
    "\n",
    "  # 역변환\n",
    "  decoded_string = tokenizer.decode(ids)\n",
    "  print(f'역변환 : {decoded_string}')\n",
    "  print()\n",
    "\n",
    "  # 역변환을 했을때 대문자가아닌 소문자로 되있는 것을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1763435338941,
     "user": {
      "displayName": "새우",
      "userId": "07446014884892897773"
     },
     "user_tz": -540
    },
    "id": "ehHUFyibZ5fr",
    "outputId": "3b1409ec-2cc6-450e-ab75-942b16f7df7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2460,  6251,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [  101,  2023,  2003,  1037,  2172,  2936,  6251, 24185,  2705,  2062,\n",
       "          2616,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Attention Mask : 실제단어 1, 패딩은 0 으로 표현\n",
    "# 여기서 패딩에 사용되는 0은 아주 작은 값을 가지고 있다.\n",
    "# -> softmax를 사용해서 0으로 변환된다^\n",
    "sentences = [\n",
    "    'short sentence',\n",
    "    'This is a much longer sentence woth more words',\n",
    "]\n",
    "\n",
    "# 여러 문장을 한꺼번에 토크나이징하고 가장 긴 문장길이에 맞춰 자동 패딩 수행\n",
    "encoded = tokenizer(\n",
    "    sentences,\n",
    "    padding = True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1763435339517,
     "user": {
      "displayName": "새우",
      "userId": "07446014884892897773"
     },
     "user_tz": -540
    },
    "id": "MQXWi5i7fx1J",
    "outputId": "98b4000e-f226-484b-fd91-159033dfbf07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 101, 1996, 4633, 2003, 3835,  102, 2292, 1005, 1055, 2175, 2005, 1037,\n",
      "        3328,  102])\n",
      "[CLS]                  101(시작)\n",
      "the                   1996(문장 A)\n",
      "weather               4633(문장 A)\n",
      "is                    2003(문장 A)\n",
      "nice                  3835(문장 A)\n",
      "[SEP]                  102(구분자)\n",
      "let                   2292(문장 B)\n",
      "'                     1005(문장 B)\n",
      "s                     1055(문장 B)\n",
      "go                    2175(문장 B)\n",
      "for                   2005(문장 B)\n",
      "a                     1037(문장 B)\n",
      "walk                  3328(문장 B)\n",
      "[SEP]                  102(구분자)\n"
     ]
    }
   ],
   "source": [
    "# token_type_ids : 두 문장을 입력할때 첫번째, 두번째 구분\n",
    "from transformers import BertTokenizer\n",
    "# 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "sentence_A= \"The weather is nice\"\n",
    "sentence_B= \"Let's go for a walk\"\n",
    "# 두 문장을 하나의 입력으로 인코딩\n",
    "encoded = tokenizer(\n",
    "    sentence_A,\n",
    "    sentence_B,\n",
    "    padding = True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "print(encoded[\"input_ids\"][0])\n",
    "tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"][0])\n",
    "for token,token_id,type_id in zip(tokens, encoded[\"input_ids\"][0], encoded['token_type_ids'][0]):\n",
    "  segment ='문장 A' if type_id == 0 else '문장 B'\n",
    "  if token == '[SEP]':\n",
    "    segment = '구분자'\n",
    "  elif token == '[CLS]':\n",
    "    segment = '시작'\n",
    "  print(f'{token:20s}{token_id.item():6d}({segment})')\n",
    "\n",
    "  # 시작하는 토큰 하나와 끝나는 토큰 하나\n",
    "  # 시작 문장1 끝, 시작할필요없이 바로 문장 2 끝 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1466,
     "status": "ok",
     "timestamp": 1763435340993,
     "user": {
      "displayName": "새우",
      "userId": "07446014884892897773"
     },
     "user_tz": -540
    },
    "id": "LuxK30n7itDk",
    "outputId": "9bb44f01-603d-4d36-f550-ce3e95cc1529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : BERT is amazing for NLP tasks\n",
      "last_hidden_state 형태 : torch.Size([1, 9, 768])\n",
      "batch_size = 1, sequence_length= 9 hidden_size = 768\n",
      "cls_embedding 형태 : torch.Size([1, 768])\n",
      "logits : tensor([[ 0.0855, -0.3234]], grad_fn=<AddmmBackward0>)\n",
      "probs : tensor([[0.6008, 0.3992]], grad_fn=<SoftmaxBackward0>)\n",
      "predicted class : 0\n"
     ]
    }
   ],
   "source": [
    "# [CLS] Token Pooling : BERT 첫번째 토큰 [CLS] 문서 전체의 요약 => 분류작업을 할때\n",
    "# 이 토큰의 출력만 가져와서 분류기(classifier)에 연결\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "# 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "sentence = 'BERT is amazing for NLP tasks'\n",
    "# 인코딩\n",
    "inputs = tokenizer(sentence,return_tensors='pt')\n",
    "# BERT 통과\n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "# 출력 형태 확인\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "print(f'입력문장 : {sentence}')\n",
    "print(f'last_hidden_state 형태 : {last_hidden_state.shape}')\n",
    "print(f'batch_size = 1, sequence_length= {last_hidden_state.shape[1]} \\\n",
    "hidden_size = {last_hidden_state.shape[2]}')\n",
    "# [CLS] 토큰 추출\n",
    "cls_embedding = last_hidden_state[:, 0, :]\n",
    "print(f'cls_embedding 형태 : {cls_embedding.shape}')\n",
    "# 분류기 (2-class)\n",
    "classifier = torch.nn.Linear(768,2)\n",
    "logits = classifier(cls_embedding)\n",
    "probs = torch.softmax(logits,dim=-1)\n",
    "print(f'logits : {logits}')\n",
    "print(f'probs : {probs}')\n",
    "print(f'predicted class : {torch.argmax(probs).item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12053,
     "status": "ok",
     "timestamp": 1763435353036,
     "user": {
      "displayName": "새우",
      "userId": "07446014884892897773"
     },
     "user_tz": -540
    },
    "id": "kSbdFqsZzmXU",
    "outputId": "db8210ce-1fa0-429b-87fe-f5a333ed6b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6087,
     "status": "ok",
     "timestamp": 1763435359128,
     "user": {
      "displayName": "새우",
      "userId": "07446014884892897773"
     },
     "user_tz": -540
    },
    "id": "XBjW1fFfv2nU",
    "outputId": "724edc1a-b1fc-4085-be6d-2a60ef4605f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :1, loss : 0.412182092666626\n",
      "epoch :1, loss : 0.7363938391208649\n",
      "epoch :2, loss : 0.3278186321258545\n",
      "epoch :2, loss : 0.633906215429306\n",
      "epoch :3, loss : 0.3037750720977783\n",
      "epoch :3, loss : 0.5865463614463806\n",
      "epoch :4, loss : 0.2668853998184204\n",
      "epoch :4, loss : 0.5134022533893585\n",
      "epoch :5, loss : 0.25739872455596924\n",
      "epoch :5, loss : 0.47351598739624023\n",
      "epoch :6, loss : 0.23052988946437836\n",
      "epoch :6, loss : 0.47282877564430237\n",
      "epoch :7, loss : 0.21135810017585754\n",
      "epoch :7, loss : 0.4615785479545593\n",
      "epoch :8, loss : 0.2339566946029663\n",
      "epoch :8, loss : 0.4230566918849945\n",
      "epoch :9, loss : 0.21104761958122253\n",
      "epoch :9, loss : 0.3843788057565689\n",
      "epoch :10, loss : 0.20207995176315308\n",
      "epoch :10, loss : 0.42876556515693665\n",
      "epoch :11, loss : 0.1410474181175232\n",
      "epoch :11, loss : 0.32445839047431946\n",
      "epoch :12, loss : 0.1274263858795166\n",
      "epoch :12, loss : 0.31781457364559174\n",
      "epoch :13, loss : 0.14033515751361847\n",
      "epoch :13, loss : 0.288566455245018\n",
      "epoch :14, loss : 0.16196230053901672\n",
      "epoch :14, loss : 0.3051156550645828\n",
      "epoch :15, loss : 0.12390954792499542\n",
      "epoch :15, loss : 0.25318901240825653\n",
      "epoch :16, loss : 0.12360524386167526\n",
      "epoch :16, loss : 0.23603776842355728\n",
      "epoch :17, loss : 0.12211667001247406\n",
      "epoch :17, loss : 0.2544477730989456\n",
      "epoch :18, loss : 0.10925162583589554\n",
      "epoch :18, loss : 0.2224770188331604\n",
      "epoch :19, loss : 0.12064467370510101\n",
      "epoch :19, loss : 0.22615791857242584\n",
      "epoch :20, loss : 0.08445927500724792\n",
      "epoch :20, loss : 0.15255102515220642\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "\n",
    "# 데이터\n",
    "texts = [\n",
    "    \"This movie is faㅁntastic!\",\n",
    "    \"Terrible film, waste of time.\",\n",
    "    \"Amazing plot and great acting.\",\n",
    "    \"Boring and predictable.\"\n",
    "]\n",
    "labels = [1, 0, 1, 0]  # 1=positive, 0=negative\n",
    "\n",
    "# 토크나이저 모델\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 모델\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)\n",
    "\n",
    "# 데이터 셋\n",
    "class SimpleDataset(Dataset):\n",
    "  def __init__(self,texts,labels):\n",
    "    self.encodings = tokenizer(texts,padding=True,truncation=True,return_tensors='pt')\n",
    "    self.labels = labels\n",
    "  def __getitem__(self, idx):\n",
    "    item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "    item['labels'] = torch.tensor(self.labels[idx])\n",
    "    return item\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "dataset = SimpleDataset(texts,labels)\n",
    "loader = DataLoader(dataset, batch_size = 2)\n",
    "\n",
    "# 학습설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(),lr=1e-5)\n",
    "# 모델을 미세조정(fine-tuning)합니다.\n",
    "# 각 epoch마다 전체 데이터셋을 반복하며 배치 단위로:\n",
    "# 1) 옵티마이저 초기화\n",
    "# 2) 입력 데이터를 장치에 할당\n",
    "# 3) 모델에 입력과 라벨 전달 후 손실 계산\n",
    "# 4) 역전파로 가중치 업데이트\n",
    "# 5) 배치 손실을 누적하여 epoch 평균 손실 계산\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "  total_loss = 0\n",
    "  for batch in loader:\n",
    "    # 1) 옵티마이저 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 2) 입력 데이터를 장치에 할당\n",
    "    inputs = {k:v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "    labels = batch['labels'].to(device)\n",
    "    # 3) 모델에 입력과 라벨 전달 후 손실 계산\n",
    "    outputs = model(**inputs,labels=labels)\n",
    "    loss = outputs.loss\n",
    "    # 4) 역전파로 가중치 업데이트\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 5) 배치 손실을 누적하여 epoch 평균 손실 계산\n",
    "    total_loss += loss.item()\n",
    "    print(f'epoch :{epoch+1}, loss : {total_loss/len(loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1763436011275,
     "user": {
      "displayName": "새우",
      "userId": "07446014884892897773"
     },
     "user_tz": -540
    },
    "id": "1eBX9gjY1GIr",
    "outputId": "312c267e-1aa8-4823-866c-c4fb19f3f10f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2205, 0.7795],\n",
       "         [0.5105, 0.4895],\n",
       "         [0.4587, 0.5413],\n",
       "         [0.6915, 0.3085],\n",
       "         [0.5720, 0.4280]], device='cuda:0'),\n",
       " tensor([1, 0, 1, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추론\n",
    "model.eval()\n",
    "sample_sentence = [\"The storyline was gripping and the acting was phenomenal!\",\n",
    "\"I laughed, I cried, and I loved every moment of it.\",\n",
    "\"Visually stunning, but the plot was kind of weak.\",\n",
    "\"It felt like a waste of two hours, incredibly boring.\",\n",
    "\"Terrible script and flat characters, I couldn't finish it.\"]\n",
    "\n",
    "# labels = [1, 1, 0, 0, 0]\n",
    "# 1=positive, 0=negative\n",
    "\n",
    "# 토큰화\n",
    "inputs = tokenizer(sample_sentence,\n",
    "                   truncation = True,\n",
    "                   padding = True,\n",
    "                   return_tensors = 'pt')\n",
    "\n",
    "# gpu / cpu 설정\n",
    "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "# .items() :\n",
    "# 딕셔너리(dictionary)의 키(key)와 값(value)을\n",
    "# 동시에 가져오기 위해 사용하는 메서드\n",
    "\n",
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "  logits = outputs.logits\n",
    "  probs = torch.softmax(logits,dim=-1)\n",
    "  pred = torch.argmax(probs,dim=-1)\n",
    "probs, pred # 1=positive, 0=negative\n",
    "# 5개중 3개 맞춤"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOFTCrQK6mFg+QP2BXeviv2",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
